[net]
batch=128
input_size=8713
momentum=0.9
decay=0.001
time_steps=40
learning_rate=0.01
#num_iterations=640000
num_iterations=10
num_threads=16

[lstm]
batch_normalize=1
output=1024
activation=linear

[lstm]
batch_normalize=1
output=1024
activation=linear

[lstm]
batch_normalize=1
output=1024
activation=linear

[lstm]
batch_normalize=1
output=1024
activation=linear

[lstm]
batch_normalize=1
output=1024
activation=linear

[connected]
batch_normalized=1
output=8713
activation=linear

[softmax]
groups=1

[cost]
type=l2
